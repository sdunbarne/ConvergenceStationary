%%% -*-LaTeX-*-
%%% convergencestationary.tex.orig
%%% Prettyprinted by texpretty lex version 0.02 [21-May-2001]
%%% on Mon Apr 26 09:12:53 2021
%%% for Steven R. Dunbar (sdunbar@family-desktop)

\documentclass[12pt]{article}

\input{../../../../etc/macros} %\input{../../../../etc/mzlatex_macros}
\input{../../../../etc/pdf_macros}

\bibliographystyle{plain}

\begin{document}

\myheader \mytitle

\hr

\sectiontitle{Convergence to the Stationary Distribution}

\hr

\usefirefox

\hr

% \visual{Study Tip}{../../../../CommonInformation/Lessons/studytip.png}
% \section*{Study Tip}

% \hr

\visual{Rating}{../../../../CommonInformation/Lessons/rating.png}
\section*{Rating} %one of
% Everyone: contains no mathematics.
% Student: contains scenes of mild algebra or calculus that may require guidance.
% Mathematically Mature: may contain mathematics beyond calculus with proofs.
Mathematicians Only:  prolonged scenes of intense rigor.

\hr

\visual{Section Starter Question}{../../../../CommonInformation/Lessons/question_mark.png}
\section*{Section Starter Question}

\hr

\visual{Key Concepts}{../../../../CommonInformation/Lessons/keyconcepts.png}
\section*{Key Concepts}

\begin{enumerate}
    \item
    \item
    \item
\end{enumerate}

\hr

\visual{Vocabulary}{../../../../CommonInformation/Lessons/vocabulary.png}
\section*{Vocabulary}
\begin{enumerate}
    \item
        Any vector \( (\pi)_{j} \) satisfying
        \begin{align}
            \sum\limits_{i} \pi_{i} P_{ij} &= \pi_{j},\\
            \sum\limits_{i} \pi_{i} &= 1.
        \end{align}
        is a \defn{stationary probability distribution} of the Markov
        chain.
    \item
        The \defn{coupling inequality} is for two random variables \( X \)
        and \( Y \) each with its own distribution.  Then for any subset
        \( A \),
        \begin{multline*}
            \abs{\Prob{X \in A} - \Prob{Y \in A}} = \\
            \abs{ \Prob{X \in A, X = Y} + \Prob{X \in A, X \ne Y } -
            \Prob{Y \in A, X = Y} - \Prob{Y \in A, X \ne Y}}.
        \end{multline*}
    \item
        A Markov chain with state space \( \mathcal{X} \) and transition
        probabilities \( P \) satisfies a \defn{minorization} condition
        if there exists a measurable subset \( C \subseteq \mathcal{X} \),
        a probability measure \( \mu \) on \( \mathcal{X} \), a constant
        \( \epsilon > 0 \), and a positive integer \( n_0 \) , such that
        \[
            P^{n_0} (x, \cdot) \ge \epsilon \mu(\cdot), x \in C.
        \]
    \item
        Call a set \( C \) satisfying a minorization condition a \defn{small
        set}.
    \item
        If \( C = \mathcal{X} \), the entire state space, then the
        Markov chain satisfies a \defn{uniform minorization condition},
        also called \defn{Doeblin's condition}.
    \item
        A Markov chain with a small set \( C \) satisfies a \defn{univariate
        drift condition} if there are constants \( 0 < \lambda < 1 \)
        and \( b < \infty \) and a function \( V :  \mathcal{X} \to [1,
        \infty] \) such that
        \[
            PV(x) \le \lambda V(x) + b \indicator{C}(x)
        \] where \( PV(x) = \E{V(X_{n+1}) \given X_n = x} \).
    \item
        A Markov chain with a small set \( C \subseteq X \) satisfies a
        \defn{bivariate drift condition} if there exists a function
        \[
            h :  \mathcal{X} \times \mathcal{X} \to [1, \infty)
        \] and some \( \alpha > 1 \) such that \( \bar{P}h(x,y) \le h(x,y)/\alpha
        \) for \( (x,y) \notin C \times C \) where
        \[
            \bar{P}h(x,y)= \E{h(X_{n+1}, Y_{n+1}) \given X_n = x, Y_n =
            y}
        \] is the expected value of \( h(X_{n+1}, Y_{n+1}) \) on the
        next iteration, when the chains start from \( x \) and \( y \)
        respectively.
\end{enumerate}

\hr

\visual{Mathematical Ideas}{../../../../CommonInformation/Lessons/mathematicalideas.png}
\section*{Mathematical Ideas}

Recall the Fundamental Theorem of Markov Chains:

\begin{theorem}[Fundamental Theorem of Markov Chains]
    For an irreducible, positive recurrent and aperiodic Markov chain \(
    \lim_{n \to \infty} (P^n)_{ij} \) exists and is independent of \( i \).
    Furthermore, letting
    \[
        \pi_j = \lim_{n \to \infty} (P^n)_{ij}
    \] then \( \pi_j \) is the unique non-negative solution of
    \begin{align}
        \sum\limits_{i} \pi_{i} P_{ij} &= \pi_{j},%
        \label{eq:convergencestationary:FTMC1}\\
        \sum\limits_{i} \pi_{i} &= 1.%
        \label{eq:convergencestationary:FTMC2}
    \end{align}
\end{theorem}
\index{Fundamental Theorem of Markov Chains}

\begin{definition}
    Any vector \( (\pi)_{j} \) satisfying equations~%
    \ref{eq:convergencestationary:FTMC1} and~%
    \ref{eq:convergencestationary:FTMC2} is a \defn{stationary
    probability distribution}%
    \index{stationary probability
    distribution}
    of the Markov chain.  A Markov chain started according to a
    stationary distribution \( (\pi_j) \) will have this distribution
    for all future times.
\end{definition}
\index{stationary probability distribution}

\begin{remark}
    This theorem says a probability transition matrix for an irreducible
    ergodic Markov chain has a \emph{left} eigenvector with
    corresponding eigenvalue \( 1 \).  This is a special case of the
    more general Perron-Frobenius Theorem.
\end{remark}

\begin{remark}
    The Fundamental Theorem says that under appropriate conditions, the
    powers of the probability transition matrix converge to the
    stationary distribution but gives no information about the rate of
    convergence.  The goal of this section is to prove some theorems and
    quantitative estimates about the rate of convergence.
\end{remark}
\index{convergence rate}

\subsection*{Convergence Theorem by Total Variation}

\begin{theorem}[Convergence Theorem by Total Variation]
    Suppose \( P \) is the transition probability matrix for an
    irreducible and aperiodic Markov chain with stationary distribution \(
    \pi \).  Then there exist constants \( \alpha \in (0,1) \) and \( C
    > 0 \) such that
    \[
        \max_{x \in \mathcal{X}} \| (P^n)_{i \cdot} - \pi \|_{TV} \le C
        \alpha^n.
    \]
\end{theorem}
\index{convergence!total variation}
\index{total variation!convergence}

\begin{proof}
    \begin{enumerate}
        \item
            Since \( P \) is irreducible and aperiodic, there exist \( r
            \) such that \( P^r \) has strictly positive entries.
        \item
            Let \( \Pi \) be the matrix with \( \mathcal{X} \) rows,
            each of which is the row vector \( \pi \).
        \item
            For sufficiently small \( \delta > 0 \), \( (P^r)_{ij} \ge
            \delta \pi_{j} \) for \( i,j \in \mathcal{X} \).
        \item
            Let \( \theta = 1-\delta \).  Define stochastic matrix \( Q \)
            by
            \[
                P^r = (1 - \theta)\Pi + \theta Q.
            \]
        \item
            Note that \( M \Pi = \Pi \) for any stochastic matrix and \(
            \Pi M =\Pi \) for any matrix with \( \pi M = \pi \).
        \item
            Claim:
            \[
                P^{rk} = (1- \theta^{k})\Pi + \theta^k Q^k.
            \] Proof by Induction:  For \( k=1 \), this is the
            definition of \( Q \).  Assume the claim is true for \( k=n \).
            \begin{align*}
                P^{r(k+1)} &= P^{rn} P^r = [(1-\theta^n)\Pi + \theta^n Q^n]P^r
                \\
                &= (1-\theta^n)\Pi P^r + (1-\theta) \theta^n Q^n \Pi +
                \theta^{n+1} Q^n Q
            \end{align*}
            Use \( \Pi P^r = \Pi \) and \( Q^n \Pi = \Pi \).
            \[
                P^{r(k+1)} = (1- \theta^{k+1})\Pi + \theta^{k+1} Q^{k+1}.
            \] Hence the relation holds for all \( k \).
        \item
            Multiply by \( P^j \), and rearrange to obtain
            \[
                P^{rk+j} - \Pi = \theta^k (Q^k P^j - \Pi).
            \]
        \item
            Sum the absolute value of row \( x_0 \) on both sides and
            divide by \( 2 \).  On the right, the absolute row \( x_0 \)
            sum from \( (Q^k P^j - \Pi) \) is at most the largest
            possible total variation distance between distributions (which
            is at most \( 1 \)).  Hence
            \[
                \| (P^{rk+j})_{i \cdot} - \pi \|_{TV} \le \theta^k.
            \]
        \item
            To finish the proof, let \( \alpha = \theta^{1/r} \) and \(
            C= 1/\theta \).
    \end{enumerate}
\end{proof}

This theorem and is proof has the advantage of being relatively
straightforward depending on matrix multiplications.  However,it is not
easily descriptive of the rate of convergence.

\subsection*{Eigenvalue analysis}

Consider the \( 3 \times 3 \) square lattice graph in Figure~%
\ref{fig:convergencestationary:sqlattice}.  The graph has \( 9 \)
vertices with \( 10 \) edges between nearest lattice neighbors.  If a
vertex has \( n \) edges then the probability of moving to a neighboring
edge or staying at the vertex is \( \frac{1}{n+1} \) uniformly. The
random walk on this graph is often colorfully characterized as a frog
hopping among lily pads or a bug leaping among plants.  The transition
probability matrix for this random walk is
\[
    \begin{pmatrix}
        1/3 & 1/3 & 0 & 1/3 & 0 & 0 & 0 & 0 & 0 \\
        1/4 & 1/4 & 1/4 & 0 & 1/4 & 0 & 0 & 0 & 0 \\
        0 & 1/3 & 1/3 & 0 & 0 & 1/3 & 0 & 0 & 0 \\
        1/4 & 0 & 0 & 1/4 & 1/4 & 0 & 1/4 & 0 & 0 \\
        0 & 1/5 & 0 & 1/5 & 1/5 & 1/5 & 0 & 1/5 & 0 \\
        0 & 0 & 1/4 & 0 & 1/4 & 1/4 & 0 & 0 & 1/4 \\
        0 & 0 & 0 & 1/3 & 0 & 0 & 1/3 & 1/3 & 0 \\
        0 & 0 & 0 & 0 & 1/4 & 0 & 1/4 & 1/4 & 1/4 \\
        0 & 0 & 0 & 0 & 0 & 1/3 & 0 & 1/3 & 1/3
    \end{pmatrix}
\]

This Markov chain has a stationary distribution
\[
    \pi = (\frac{1}{11}, \frac{4}{33}, \frac{1}{11}, \frac{4}{33}, \frac
    {5}{33}, \frac{4}{33}, \frac{1}{11}, \frac{4}{33}, \frac{1}{11}).
\] This Markov chain is ergodic and aperiodic.  All states are
accessible and all states communicate.  This Markov chain has no
transient states and all states are recurrent.  This Markov chain has no
absorbing states.

\begin{figure}
    \centering
\begin{asy}
size(5inches);

real myfontsize = 12;
real mylineskip = 1.2*myfontsize;
pen mypen = fontsize(myfontsize, mylineskip);
defaultpen(mypen);

real marge=1mm;
pair z1=(0, 2), z2=(1, 2), z3=(2, 2);
pair z4=(0, 1), z5=(1, 1), z6=(2, 1);
pair z7=(0, 0), z8=(1, 0), z9=(2, 0);

transform r=scale(1.0);

object state1=draw("1",ellipse,z1,marge),
state2=draw("2",ellipse,z2,marge),
state3=draw("3",ellipse,z3,marge),
state4=draw("4",ellipse,z4,marge),
state5=draw("5",ellipse,z5,marge),
state6=draw("6",ellipse,z6,marge),
state7=draw("7",ellipse,z7,marge),
state8=draw("8",ellipse,z8,marge),
state9=draw("9",ellipse,z9,marge);

add(new void(picture pic, transform t) {
    draw(pic, point(state1,E,t)--point(state2,W,t));
    draw(pic, point(state1,S,t)--point(state4,N,t));
});

add(new void(picture pic, transform t) {
    draw(pic, point(state2,E,t)--point(state3,W,t));
    draw(pic, point(state2,S,t)--point(state5,N,t));
});

add(new void(picture pic, transform t) {
    draw(pic, point(state3,S,t)--point(state6,N,t));
});

add(new void(picture pic, transform t) {
    draw(pic, point(state4,E,t)--point(state5,W,t));
    draw(pic, point(state4,S,t)--point(state7,N,t));
});

add(new void(picture pic, transform t) {
    draw(pic, point(state5,E,t)--point(state6,W,t));
    draw(pic, point(state5,S,t)--point(state8,N,t));
});

add(new void(picture pic, transform t) {
    draw(pic, point(state5,E,t)--point(state6,W,t));
    draw(pic, point(state5,S,t)--point(state8,N,t));
});

add(new void(picture pic, transform t) {
    draw(pic, point(state6,S,t)--point(state9,N,t));
});

add(new void(picture pic, transform t) {
    draw(pic, point(state7,E,t)--point(state8,W,t));
});

add(new void(picture pic, transform t) {
    draw(pic, point(state8,E,t)--point(state9,W,t));
});
\end{asy}
    \caption{A \( 3 \times 3 \) square lattice graph with uniform
    transition probabilities.}%
    \label{fig:convergencestationary:sqlattice}
\end{figure}

The eigenvalues are
\begin{align*}
    \lambda_0 &= 1 \\
    \lambda_1 &= \frac{7 + \sqrt{97}}{24} \approx 0.702 \\
    \lambda_2 &= \frac{7 + \sqrt{97}}{24} \approx 0.702 \\
    \lambda_3 &= \frac{1}{3} \\
    \lambda_4 &= \frac{1}{4} \\
    \lambda_5 &= \frac{1}{4} \\
    \lambda_6 &= \frac{7 - \sqrt{97}}{24} \approx -0.119 \\
    \lambda_7 &= \frac{7 - \sqrt{97}}{24} \approx -0.119 \\
    \lambda_8 &= -\frac{7}{15} \approx -0.467
\end{align*}
The corresponding left eigenvectors are

Suppose the random walk starts from the center of the square lattice,
state \( 5 \), that is \( X_0 \sim (0,0,0,0,1,0,0,0,0) \).

\subsection*{Coupling and Minorization}

The idea of coupling is to create two different copies of a random
object, and compare them.  A key idea is the \defn{coupling inequality}.%
\index{coupling inequality}
Suppose \( X \) and \( Y \) are two random variables, each with its own
distribution.  Then for any subset \( A \),
\begin{multline*}
    \abs{\Prob{X \in A} - \Prob{Y \in A}} = \\
    \abs{ \Prob{X \in A, X = Y} + \Prob{X \in A, X \ne Y } - \Prob{Y \in
    A, X = Y} - \Prob{Y \in A, X \ne Y}}
\end{multline*}
However, \( \Prob{X \in A, X = Y} = \Prob{Y \in A, X = Y} \) since both
refer to the same event.  Also, \( 0 \le \Prob{X \in A, X \ne Y} \le
\Prob{X \ne Y} \) and \( 0 \le \Prob{Y \in A, X \ne Y} \le \Prob{X \ne Y}
\) so \( \Prob{X \in A, X \ne Y} - \Prob{Y \in A, X \ne Y} \le \Prob{X
\ne Y} \).  Hence
\[
    \abs{\Prob{X \in A} - \Prob{Y \in A}} \le \Prob{X \ne Y}.
\] Since the upper bound is uniform over \( A \),, this gives a bound on
the total variation distance
\begin{equation}\label{eqn:convergencestationary:tvbound}
    \|
    \operatorname{dist}
    (X) =
    \operatorname{dist}
    (Y) \|_{TV} = \sup_{A \subseteq \mathcal{X}} \abs{\Prob{X \in A} -
    \Prob{Y \in A}} \le \Prob{X \ne Y}.
\]
\begin{definition}
    A Markov chain with state space \( \mathcal{X} \) and transition
    probabilities \( P \) satisfies a \defn{minorization condition}%
    \index{minorization condition}
    if there exists a measurable subset \( C \subseteq \mathcal{X} \), a
    probability measure \( \mu \) on \( \mathcal{X} \), a constant \(
    \epsilon > 0 \), and a positive integer \( n_0 \), such that
    \[
        P^{n_0} (x, \cdot) \ge \epsilon \mu(\cdot), x \in C.
    \] Call a set \( C \) satisfying a minorization condition a \defn{small
    set}.%
    \index{small set}
    In particular, if \( C = \mathcal{X} \), the entire state space,
    then the Markov chain satisfies a \defn{uniform minorization
    condition},%
    \index{uniform minorization condition}
    also called \defn{Doeblin's condition}.%
    \index{Doeblin's condition}
\end{definition}

The uniform minorization condition implies there exists a common overlap
of size \( \epsilon \) between all of the transition probabilities.
This allows a coupling construction of two different copies \( X_n \)
and \( X_n' \) of a Markov chain as follows.  Assume for now that \( n_0
= 1 \).
\begin{enumerate}
    \item
        Choose \( X_0 \sim \mu_0(\cdot) \) and \( X_0' \sim \pi(\cdot) \)
        independently.
    \item
        If \( X_n = X_n' \), choose \( z \sim P(X, \cdot) \) and let \(
        X_{n+1}' = X_{n+1} = z \).  Now the chains are coupled and the
        two chains will remain equal forever.
    \item
        If \( X_n \ne X_n' \), flip a coin whose probability of heads is
        \( \epsilon \).  If the coin shows heads, choose \( z \sim \mu(\cdot)
        \), and let \( X_{n+1}' = X_{n+1} = z \).  Otherwise, update \(
        X_{n+1} \) and \( X_{n+1}' \) independently with probabilities
        given by
        \begin{align*}
            \Prob{X_{n+1} \in A} &= \frac{P(X_n, A) - \epsilon \mu(A)}{1-\epsilon}
            \\
            \Prob{X_{n+1}' \in A} &= \frac{P(X_n', A) - \epsilon \mu(A)}
            {1-\epsilon} \\
        \end{align*}
\end{enumerate}

The minorization condition guarantees that the residual probabilities
are nonnegative and are probability measures since
\[
    \frac{P(X_n, \mathcal{X}) - \epsilon \mu(\mathcal{X})}{1-\epsilon} =
    \frac{1-\epsilon}{1-\epsilon} = 1.
\]

\begin{lemma}
    \( P(X_{n+1} \in A \given X_n = x) = P(x,A) \) and \( P(X_{n+1}' \in
    A \given X_n' = x) = P(x,A) \) for any \( x \in \mathcal{X} \)
\end{lemma}

\begin{proof}
    If the two chains are unequal at time \( n \), then
    \begin{align*}
        \Prob{X_{n+1} \in A \given X_n = x} &= \Prob{X_{n+1} \in A,\text
        { Heads} \given X_n = x} + \Prob{X_{n+1} \in A,\text{ Tails}
        \given X_n = x} \\
        &= \Prob{\text Heads} \Prob{X_{n+1} \in A \given X_n = x, \text{%
        Heads}} + \Prob{X_{n+1} \in A \given X_n = x, \text{ Tails} } \\
        &= \epsilon \mu(A) + (1-\epsilon) \frac{\Prob{X_n, \mathcal{X} -
        \epsilon \mu(\mathcal{X})}}{1-\epsilon} \\
        &= P(x,A)
    \end{align*}
\end{proof}

\begin{theorem}[Minorization Estimate]
    If \( X_n \) is a Markov chain on \( \mathcal{X} \) with transition
    probabilities satisfying a uniform minorization condition for some \(
    \epsilon > 0 \), then for any positive integer \( n \) and any \( x
    \in \mathcal{X} \)
    \[
        \|
        \operatorname{dist}
        (X_n) - \pi \|_{TV} \le (1-\epsilon)^{\lfloor n/n_0 \rfloor}.
    \]
\end{theorem}
\index{minorization estimate}

\begin{proof}
    In \( n_0 > 1 \), use the construction above for the times \( n = 0,
    n_0, 2n_0, \dots \) with \( n+1 \) replaced by \( n + n_0 \) and
    with \( P \) replaced by \( P^{n_0} \).  Then fill in the
    intermediate state \( X_n \) for \( j n_0 < n < (j+1) n_0 \) from
    the appropriate conditional distribution given the
    already-constructed values of \( X_{j n_0} \) and \( X_{(j_+1)n_0} \).

    Since \( X_0' \sim \pi \) and \( \pi \) is stationary, then \( X_n'
    \sim \pi \) for all \( n \).  Every \( n_0 \) steps, the two chains
    have probability at least \( \epsilon \) of coupling because the
    coin comes up Heads.  So

    \( \Prob(X_n \ne X_n') \le (1-\epsilon)^{\lfloor n/n_0 \rfloor} \).
\end{proof}

Assume \( \mathcal{X} \) is finite and for some \( n_0 \) there is at
least one state \( j \in \mathcal{X} \) such that the \( j \)th column
of \( P^{n_0} > 0 \) for all \( x \in \mathcal{X} \).  Then set \(
\epsilon = \sum_{x \in \mathcal{X}} \min_{i \in \mathcal{X}} (P^{n_0})_{i,j}
> 0 \) and \( \mu(j) = \epsilon^{-1} (P^{n_0})_{i,j} \) so \( (P^{n_0})_
{i,j} \ge \epsilon \mu(j) \) for all \( i,j \in \mathcal{X} \).  That
is, an \( n_0 \)-step minorization condition is satisfied with \(
\epsilon \).

\begin{example}
    Consider the random walk on the \( 3 \times 3 \) square lattice.
    The transition probabilities do not satisfy a minorization condition
    since every column has some zeros.  However, in \( P^2 \), column
    has all positive values,
    \[
        \begin{pmatrix}
            \frac{5}{18} & \frac{7}{36} & \frac{1}{12} & \frac{7}{36} &
            \frac{1}{6} & 0 & \frac{1}{12} & 0 & 0\\
            \frac{7}{48} & \frac{67}{240} & \frac{7}{48} & \frac{2}{15}
            & \frac{9}{80} & \frac{2}{15} & 0 & \frac{1}{20} & 0\\
            \frac{1}{12} & \frac{7}{36} & \frac{5}{18} & 0 & \frac{1}{6}
            & \frac{7}{36} & 0 & 0 & \frac{1}{12}\\
            \frac{7}{48} & \frac{2}{15} & 0 & \frac{67}{240} & \frac{9}{80}
            & \frac{1}{20} & \frac{7}{48} & \frac{2}{15} & 0\\
            \frac{1}{10} & \frac{9}{100} & \frac{1}{10} & \frac{9}{100}
            & \frac{6}{25} & \frac{9}{100} & \frac{1}{10} & \frac{9}{100}
            & \frac{1}{10}\\
            0 & \frac{2}{15} & \frac{7}{48} & \frac{1}{20} & \frac{9}{80}
            & \frac{67}{240} & 0 & \frac{2}{15} & \frac{7}{48}\\
            \frac{1}{12} & 0 & 0 & \frac{7}{36} & \frac{1}{6} & 0 &
            \frac{5}{18} & \frac{7}{36} & \frac{1}{12}\\
            0 & \frac{1}{20} & 0 & \frac{2}{15} & \frac{9}{80} & \frac{2}
            {15} & \frac{7}{48} & \frac{67}{240} & \frac{7}{48}\\
            0 & 0 & \frac{1}{12} & 0 & \frac{1}{6} & \frac{7}{36} &
            \frac{1}{12} & \frac{7}{36} & \frac{5}{18}
        \end{pmatrix}
        .
    \] The walk starting in state \( 5 \) will always have at least a
    probability \( \frac{9}{80} \) that it will return to state \( 5 \)
    in two steps.  Take the minorization condition as
    \[
        \epsilon = \sum_{x \in \mathcal{X}} \min_{j \in \mathcal{X}} (P^2)_
        {i,j} = 0 + 0 + 0 + 0 + \frac{9}{80} + 0 + 0 + 0 + 0 = \frac{9}{80}
    \] and \( \mu(j) = \epsilon^{-1} (P^2)_{i,j} \).  By the Theorem
    with \( n_0 = 2 \) and \( \epsilon = \frac{9}{80} \),
    \[
        \|
        \operatorname{dist}
        (Xn) - \pi \|_{TV} \le (1-\frac{9}{80})^{\lfloor n/2 \rfloor} -
        \left( \frac{71}{80} \right)^{\lfloor n/2 \rfloor}.
    \] To get the distribution of the random walk within \( 0.01 \) of
    the stationary distribution requires \( 78 \) steps.  Compare this
    to the estimate of \( 6 \) steps using the eigenvalues of \( P \).
\end{example}

\subsection*{An Example of the Cut-Off Phenomenon}

% https://pages.uoregon.edu/dlevin/MARKOV/mcmt2e.pdf
% https://sites.tufts.edu/vrdi/files/2019/06/Markov-Chains-and-Mixing-Times.pdf

This subsection shows  some sharper estimates of the rate of
convergence are possible in specific cases.  Here the case of random
walk on the hypercube exhibits the \emph{cut-off} phenomenon.

Let \( Q^n \), the $n$-dimensional hypercube graph,
with vertices or node set $V(Q^n) = \set{x_0, x_1, \dots x_n} =
\set(0,1}^n$ and edge set $E(Q^n) = \setof{(x,y)}{x, y \text{ differ in
one coordinate}}$.\index{hypercube}   As a notational convenience, let $\bar{0} = (0,
dots, 0)$ denote the origin and $\bar{1} = (1, dots, 1)$ be the
extreme vertex of the hypercube.

A random walk on this graph is the 
sequence $X_0, X_1, \dots, X_{n-1}, X_n, \dots $ where given
$X_{n-1}$, choose
$X_n$ uniformly at random from the nodes adjacent to $x_{n-1}$.  A
practical way to implement this random walk is to choose a coordinate
$j \in \set{1,2, \dots, n}$ uniformly at random and flip the bit at
$j$ from $0$ to $1$ or from $1$ to $0$.  For example, on the
$3$-dimensional cube a walk at $011$ will move to $111$ is position
$1$ is selected, to $001$ if position $2$ is selected, and $010$ if
position $3$ is selected.
As $n
\to \infty$, the distribution of $X_n$ converges to the uniform
distribution $\pi$ on $V(Q^n)$.  (See the exercises.)  This random
walk has the annoying disadvantage of being periodic with period two, so
instead consider the \emph{lazy random walk} sequence $X_0, X_1, \dots, X_{n-1}m X_n, \dots $ where given
$X_{n-1}$, first choose to remain at $X_{n-1}$ with probability
$\frac{1}{2}$.  Alternatively, with probability $\frac{1}{2}$ choose
to move to  
$X_n$ selected uniformly at random from the nodes adjacent to
$x_{n-1}$.  A
practical way to implement this random walk is to choose a coordinate
$j \in \set{1,2, \dots, n}$ uniformly at random and replacing the bit
in that position with the value of a fair Bernoulli random value.   the bit at
$j$ from $0$ to $1$ or from $1$ to $0$.  The lazy random walk also converges to the uniform
distribution $\pi$ on $V(Q^n)$.  (See the exercises.)

The intention here to understand the rate of convergence to the stationary
distribution in the Total Variation norm.  More precisely, given fixed
$\epsilon$
what the the smallest $t = t(n)$ such that
\[
  \| \Prob{X_t} - \pi \|_{TV} < \epsilon
\]
as a function $n$.

The investigation proceeds by coupling.   Start one random walk $X$ at
$\bar{0}$, and start another random walk $Y$ ``far'' from $\bar{0}$.  
Define $\tau_y = \inf \setof{t}{X_t = Y_t, Y_0 = y}$.  Then define a combined
random walk $X_t = Y_t$ for $t > \tau_y$.  Since neither random walk is
dependent on history, but only on the current state, the probability
of states in the future is the same for each walk.  Combining the law
of total probability with the triangle inequality
\begin{align*}
  & \| \Prob{X_t = \cdot} - \Prob{Y_t} \|_{TV} \le \\
  & \qquad \| \Prob{X_t = \cdot \given \tau_y \le t} -
     \Prob{Y_t} = \cdot \given \tau_y \le t \|_{TV} \Prob{\tau_y \le t} +\\
  & \qquad \| \Prob{X_t = \cdot \given \tau_y > t} -
    \Prob{Y_t} = \cdot \given \tau_y \le t \|_{TV} \Prob{\tau_y > t}
  & \qquad = \| \Prob{X_t = \cdot \given \tau_y > t} -
    \Prob{Y_t} = \cdot \given \tau_y \le t \|_{TV} \Prob{\tau_y > t}
  & \le \Prob{\tau_y > t}.
\end{align*}
Notice that the first summand is $0$
\[
\| 0 = \Prob{X_t = \cdot \given \tau_y \le t} -
     \Prob{Y_t} = \cdot \given \tau_y \le t \|_{TV} \Prob{\tau_y \le t}
\]
{Why is this so, it seems that it ought to be the second summand.}   
and the last inequality follows because $\| \cdot \|_{TV} \le 1$.
This inequality is basically the Strong Markov Property.

Recall that
\begin{align*}
  \| \Prob{X_t = \cdot} - \pi \|_{TV} &\le
  \max_{y} \| \Prob{X_t = \cdot} - \Prob{Y_t \given Y_0 = y} \|_{TV} \\
  &\le \| \Prob{X_t = \cdot} - \Prob{Y_t \given Y = \bar{1}} \|_{TV} \\
  &\le \Prob{\tau_{\bar{1}}} > t                                      
\end{align*}

Now consider the following schematic characterization of the
hypercube.  Let the \defn{Hamming weight} of a vertex be the sum of the
coordinates of the vertex, ranging from Hamming weight $0$ at $\bar{0}$ to $n$
at $\bar{1}$.  As notation, use $\operatorname{ht}(x)$ for the hieght
of vertex $x$.

\begin{figure}
  \centering
  \begin{asy}
settings.outformat = "pdf";

import graph;

size(5inches);

real myfontsize = 12;
real mylineskip = 1.2*myfontsize;
pen mypen = fontsize(myfontsize, mylineskip);
defaultpen(mypen);

real center = 7;
real halfwidth = 4;		// perfect square
real height = 2 * sqrt(halfwidth) + 2 * halfwidth;
real l = center - halfwidth;
real r = center + halfwidth;
real h1 = sqrt(halfwidth);
real h2 = halfwidth;
real height = h1 + h2 + h1;
real rr = r + 1;

real f1( real x ) { return sqrt( abs( x - center ) ); }
real f2( real x ) { return height - sqrt(abs( x - center ) );} 

draw( graph(f1, l, r) );
draw( (l, h1)--(l, h1+h2) );
draw( (r, h1)--(r, h1+h2) );
draw( graph(f2, l, r) );

draw( (l, h1)--(r,h1), dashed);
draw( (l, height/2)--(r,height/2), dashed);
draw( (l, h1+h2)--(r,h1+h2), dashed);

label("$\bar{0}$", (center, 0), S);
label("$\bar{1}$", (center, height), N);

yaxis(L="Hamming Weight", ymin=0, ymax = height, autorotate=false);
ytick(Label("$0$", (0,0), E), (0,0));
ytick(Label("$n/2 - O(\sqrt{n})$", (0,h1), SE), (0, h1));
ytick(Label("$n/2$", (0, height/2), E), (0,height/2));
ytick(Label("$n/2 + O(\sqrt{n})$", (0,h1+h2), NE), (0, h1+h2));
ytick(Label("$n$", (0,height), E), (0,height));

Label L1= Label("steps $\approx \frac{n}{2} \log n$", align=(0,0),
		position=MidPoint, filltype=Fill(white));
draw((rr,0)--(rr,h1), L=L1, bar=BeginBar, arrow=EndArrow);
draw((rr,height)--(rr,h1+h2), L=L1, bar=BeginBar, arrow=EndArrow);
\end{asy}
  \caption{Caricature of the hypercube in terms of the Hamming weight of the
    vertices.}
  \label{fig:convergencestationary:hypercube}
\end{figure}

The plan for the remander of the proof is show that both walks get to
the bulk of the hypercube in $\frac{n}{2} \log n$ steps, and then it
takes an additional $O(n)$ steps for them to meet.

An algorithm to simulate $X_t$ and $Y_t$ simultaneously is the following
Given $X_{t-1} = x$ and $Y_{t-1} = y$
Choose $j \in \set{1, 2, \dots, n}$ uniformly at random.
Replace $x_i$ and $y_i$ with the \emph{same} random bit chosen as the
value of a fair Bernoulli random value.   For example, on
$10$-dimensional hypercube suppose the $X$
random walk is at $0011010011$ and the $Y$ random walk is at
$0110001010$.  Position $6$ is selected at random, and the Bernoulli
random variable comes up $1$.  The $6$th coordinate is $1$, leaving
$X$ unchanged, but the $Y$ chain moves to $0110011010$.  This example
makes it obvious that each of the walks constructed in this way is a lazy random walk on the
hypercube.

If $\tau$ is the first time when all the coordinates have been
selected at least once, then the, then the two walks agree with each
other from time $\tau$ onward.  If the two initial states agree in
some coordinates, the first time the walks coincide could be strictly
before $\tau$.  Let $R_t$ be the number of unselected coordinates at
time $t$.  The random variable decreases rapidly at first, then it
slows down as it becomes harder to select an unused coordinates.  This
is basically the coupon collectors problem, so
$\E{R_t} = n(1 - 1/n)^t$.

\begin{remark}
  The usual formulation of the coupon colle tors problems
  has \( n \) different types of coupons or
    prizes in a cereal box.  On each draw, one obtains a coupon or prize
    equally likely to be any one of the \( n \) types.  The goal is to
    find the expected number of coupons one needs to gather before
    obtaining a complete set of at least one of each type.
\end{remark}


\begin{theorem}
  \begin{enumerate}
  \item Let $X_t, Y_t$ be coupled Markov chains with $X_0 = x$ and
    $Y_0 = y$.
  \item Let $\Probsub{x,y}{\cdot}$ be the probability distribution for
    $X_t, Y_t$.
  \item Let $\tau_{\text{coal}}$ be the coalescence time of the
    chains, that is
    \[
      \tau_{\text{coal}} = \min \setof{t}{X_s = Y_s, s \ge t}.
    \end{enumerate}
    Then
    \[
      \| P^t(x, \cdot) - P^t(y,\cdot)\|_{TV} \le
      \Probsub{x,y}{\tau_{\text{coal}} > t}
    \]
\end{theorem}

\begin{proof}
  \begin{enumerate}
  \item The first observation is that
    $P^t(x, z) = \Probsub{x,y}{X_t = z}$ and
    $P^t(y, z) = \Probsub{x,y}{Y_t = z}$.
  \item Using the bound on the total variation metric observed in
    \eqref{eqn:convergencestationary:tvbound},
    \[
      \| P^t(x, \cdot) - P^t(y,\cdot)\|_{TV} \le \Probsub{x,y}{X_t \ne
        Y_t}.
    \]
\item But $\Probsub{x,y}{X_t \ne
        Y_t} = \Probsub{x,y}{\tau_{\text{coal}} > t}$ which completes
      the proof.
  \end{enumerate}
\end{proof}

Two convenient notations  are
\[
  d(t) = \max_{x \in \mathcal{X}} \| P^t(x, \cdot) - \pi \|_{TV}
\]
and 
\[
  \bar{d}(t) = \max_{x \in \mathcal{X}} \| P^t(x, \cdot) -
  P^t(y,\cdot)\|_{TV}.
\]

\begin{lemma}
  \[
    d(t) \le \bar{d}(t) \le 2 d(t)
\end{lemma}

\begin{proof}
  \begin{enumerate}
   \item For the first inequality, state with the simple property of
     stationarity $\pi(z) = \sum_{y \in \mathcal{X}}
     \pi(y) \left[ P^t(y,z)$.
   \item Now for any set $A$ of states, sum the previous over the
     states $z \in A$ so
     $\pi(A) = \sum_{y \in \mathcal{X}} \pi(y) \left[ P^t(y,A}$
   \item Using the row sum probability for a Markov chain is $1$ and
     applying absolute values
     \[
       \abs{P^t(x,A)} - \pi(A)} = \abs{\sum_{y \in \mathcal{X}}
     \pi(y) \left[ P^t(x,A) - P^{t}(y,A)\right]}.
   \]
   \item By the triangle inequality, the definition of total variation
     as the maximum difference over all events and the definition of $\bar{d}(t)$
     \[
       \abs{\sum_{y \in \mathcal{X}} \pi(y) \left[ P^t(x,z) -
           P^{t(y,z)}\right]} \le \sum_{y \in \mathcal{X}} \pi(y) \| P^t(x,\cdot) -
           P^t(y,\cdot)\|_{TV} \le \bar{d}(t).
         \]
  \item Maximize the left side over $X$ and $A$ yields $d(t) \le
           \bar{d}(t)$.
  \item For the second inequality, start with
    the triangle inequality for the total variation distance
    \[
      \| P^t(x, \cdot) - P^t(y,\cdot)\|_{TV} \le
      \| P^t(x, \cdot) - \pi\|_{TV} + \| \pi -  P^t(y,\cdot)\|_{TV}.
    \]
  \item Then   
    \[
      \bar{d}(t) = \max_{x \in \mathcal{X}} \| P^t(x, \cdot) - P^t(y,\cdot)\|_{TV} \le
      \max_{x \in \mathcal{X}}\| P^t(x, \cdot) - \pi\|_{TV} + \max_{y
        \in \mathcal{X}} \| \pi -  P^t(y,\cdot)\|_{TV} = 2 d(t).
    \]
  \end{enumerate}
\end{proof}

\begin{lemma}
     Sample uniformly with replacement
    from the set \( \set{1, 2, \dots  n} \).  Let \( \tau \) be the number of draws
    required until each element has been drawn at least once.  Then
    \[
        \Prob{\tau > n \log n + c n} \le \EulerE^{-c}
    \] for \( c \ge 0 \) and \( n \ge 1 \).
\end{lemma}


\begin{proof}
    Let \( m = n \log n + c n \).  For each integer \( b \) let \( A_b \)
    be the event ``integer \( b \) not drawn in the first \( m \) draws.
    Then
    \[
        \Prob{ \tau > m} = \Prob{ \bigcup_{b=1}^n A_b } \le \sum_{b=1}^n \Prob{A_b} =
        n \left( 1 - \frac{1}{n} \right)^m \le n \EulerE^{-m/n} = \EulerE^
        {-c}.
      \]
      See the exercises for a proof of the second inequality.
\end{proof}

\begin{corollary}
  \[
    t_{\text{mix}} \le n \log n + \log(1/\epsilon) n.
  \]
\end{corollary}

Given $R_t$, the Markov chains $X_t$ and $Y_t$ have Hamming weights that are
binomial random variables,
\begin{align*}
\operatorname{wt}(X_t) &= \operatorname{Bin}(n - R_t, 1/2) \\
\operatorname{wt}(X_t) &= \operatorname{Bin}(n - R_t, 1/2) + R_t.
\end{align*}

Therefore, at time $t \approx \frac{n}{2} \log n$
\begin{align*}
  \E{\operatorname{ht}(X_t)} &\approx \frac{n}{2} - \frac{\sqrt{n}}{2} \\
  \E{\operatorname{ht}(Y_t)} &\approx \frac{n}{2} + \frac{\sqrt{n}}{2}
\end{align*}
and
\begin{align*}
  \sigma{\operatorname{ht}(X_t)} &= O(\sqrt{n}) \\
  \sigma{\operatorname{ht}(Y_t)} &= O(\sqrt{n}),
\end{align*}
where $\sigma(X)$ is the standard deviation of a random variable.

\begin{theorem}
  Let $\epsilon > 0$.  Then there exists an $\alpha \ge 0$ so that for
  $t(\alpha) = \frac{n}{2} \log n + \alpha n$, $\Prob{\tau >
    t(\alpha)} < \epsilon$.
\end{theorem}

\begin{lemma}\label{thm:convergence:lem713}
  Consider the coupon collecting problem with $n$ distinct coupon
types, and let $I_j(t)$ be the indicator of the event that the $j$-th coupon has not been
collected by time $t$. Let $R_t = \sum_{\nu = 1}^n I_j(t)$
be the number of coupon types not collected
by time $t$.
The random variables $I_j(t)$ are negatively correlated, and letting $p =(1 − 1
n)^t$, we have for $t \ge 0$,
\begin{align*}
  \E(R_t) &= n p \\
  \Var{R_t} &= n p (1- p) \le \frac{n}{4}.
\end{align*}
\end{lemma}

\begin{remark}
  With this notation, notice the similarity to the mean and variance
  of a binomial random variable.
\end{remark}

\begin{proof}
  \begin{enumerate}
  \item Since $I_j(t) = 1$ if and only if the first $t$ coupons are
    not of type $j$, immediately
\begin{align*}
  \E(I_j(t) ) &= \left( 1 - \frac{1}{n} \right)^n = p \\
  \Var{I_j(t)} &= p (1- p).
\end{align*}
\item Similarly, for $j \ne k$,
  \[
    \E{ I_j(t) I_{k(t)} = \left( 1 - \frac{2}{n} \right)^t.
  \]
\item Therefore
  \[
    \Cov{I_{j(t} I_{k(t)}} = \left( 1 - \frac{2}{n} \right)^t - \left(
      1 - \frac{1}{n} \right)^{2t} \le 0.
  \]
  \end{enumerate}
\end{proof}

\begin{definition}
  When $\mu$ is a probability distribution on $\mathcal{X}$, and $f :
  \mathcal{X} \to \Lambda$ is a function on $\mathcal{X}$, write $\mu
  f^{-1}$ for the probability distribution defined by
  \[
    (\mu f^{-1})(A) = \mu(f^{-1}(A))
  \]
  for $A \subset \Lambda$. When $X$ is an $\mathcal{X}$-valued random
  variable with distribution $m$, then $f(X)$ has distribution $\mu
  f^{-1}$ on $\Lambda$.
\end{definition}

\begin{lemma}\label{thm:convergencestationary:lem710}
  \begin{enumerate}
  \item Let $\mu$ and $\nu$ be probability distributions on
    $\mathcal{X}$.
  \item Let $f:X \to \Lambda$ be a function on $\mathcal{X}$ where
    $\Lambda$ is a finite set.
  \end{enumerate}
  Then $\| \mu - \nu \|_{TV} \ge \| \mu f^{-1} - \nu f^{-1} \|_{TV}.
\end{lemma}

\begin{proof}
  \begin{enumerate}
  \item First (read the parentheses carefully)
    \[
      \abs{\mu f^{-1}(B) - \nu f^{-1}(B)} =  \abs{\mu (f^{-1}(B)) -
        \nu (f^{-1}(B))}.
    \]
    \item Then
    \[
      \max_{B \subst \Lambda}\abs{\mu f^{-1}(B) - \nu f^{-1}(B)} \le
      \max_{A \subset \mathcal{X}}\abs{\mu (A) - \nu (A)}.
    \]

  \end{enumerate}
\end{proof}

\begin{remark}
  Use this lemma to lower bound the distance of some
chain from stationarity in terms of the corresponding distance for a
projection or lumping
of that chain. To do so, take Λ to be the relevant partition
of X.
\end{remark}

\begin{proposition}\label{thm:convergencestationary:prop79}
  \begin{enumerate}
  \item Let $f:\mathcal{X} \to \Reals$.
  \item Let $\mu$, $\nu$ be two probability distributions on
    $\mathcal{X}$.
  \item Define $\sigma_{\star}^2 = \max{ \Varsub_{\mu}(f),
      \Varsub_{\nu}(f)}$.
  \item Suppose $\abs{ \Esub{\mu}{f} - \Esub{\nu}(f)} \ge r \sigma_{\star}$.
  \end{enumerate}
  Then
  \[
    \| \mu - \nu \|_{TV} \ge 1 - \frac{8}{r^2}.
  \]
\end{proposition}

\begin{proof}
  \begin{enumerate}
  \item Suppose without loss of generality that $\Esub{\mu}{f}} \le
  \Esub{\nu}{f}}$.
\item Let $A = (\Esub{\mu}{f}} + r\sigma_{\star}/2, \infty)$, then
Chebyshev's Inequality yields that
  $ \mu f^{-1}(A) \le \frac{4}{r^2} $ and $\nu f^{-1}(A) \ge  1 -
  \frac{4}{r^2}$.
\item Then
  \[
    \| \mu f^{-1} -\nu f^{-1} \|_{TV} \ge 1 - \frac{8}{r^2}
  \]
\item Then apply Lemma \ref{thm:convergencestationary:lem710} to
  complete the proof.
  \end{enumerate}
\end{proof}

\begin{corollary}\label{thm:convergencestationary:cor79}
  Suppose For a Markov chain $X_t$ with transition probability matrix
  $P$, the function $f$ satisfies
  \[
    \abs{ \Esub{x}{f(X_t)} - \Esub{\pi}{f}} \ge r \sigma_{\star}
  \]
  then
  \[
    \| P^t(x, \cdot) - \pi \|_{TV} \ge 1 - \frac{8}{r^2}
\end{corollary}

\begin{proof}
  \begin{enumerate}
  \item See teh exercises.
  \end{enumerate}
\end{proof}

\begin{proposition}
  For the lazy random walk on the $n$-dimensional hypercube
  \[
    d \left( \frac{1}{2} n \log n - \alpha n \right) \ge 1 - 8^{2 -
      2\alpha}.
  \]  
\end{proposition}

\begin{proof}
  \begin{enumerate}
  \item Apply Proposition \ref{thm:convergencestatstionary:prop79}
    with $f = \operatorname{wt}$.  The walker started $\bar{1}$ is
    $X_t$.
  \item As $\pi$ is uniform on ${0,1}^n$, the distribution of the
    random variable $W$ is $\operatorname{Bin}(n,1/2)$, so
    $\Esub{\pi}{W} = n/2$ and $\Varsub{x}{W} = n/4$.
  \item Recall that $R_t$ is the number of coordinates not updated by
    time $t$.  When starting from $\bar{1}$, the conditional
    distribution of $\operatorname{wt}(X_t)$, given $R_t = r$ is $r +
    \operatorname{Bin}(n-r, 1/2)$.
  \item Consequently,
    \[
      \Esub{1}(\operatorname{W}(X_{t} \given R_t} = R_t + \frac{(n-R_t)}{2} =
    \frac{1}{2}(R_t + n).
  \item Using Lemma \ref{thm:convergence:lem713}
    \[
      \Esub{\bar{1}}{\operatorname{W}(X_t}} = \frac{n}{2} \left[ 1 + \left( 1-
      \frac{1}{n} \right)^t \right].
    \]
  \item Recall the identity for variance using conditionals, applied
    here as
    \begin{align*}
      \Varsub{\bar{1}}{\operatorname{W}(X_t)} &= \Varsub{\bar{1}}{\E{\operatorname{W}(X_t)} \given R_t}
                                 + \Esub{\bar{1}}{\Varsub{\bar{1}}{\operatorname{W}(X_t)} | R_t} \\
      &= \frac{1}{4} \Varsub{\bar{1}}{\operatorname{W}(X_t} + \frac{1}{4} \left[ n - \Esub{\bar{1}(R_t} \right].
    \end{align*}
  \item Again using Lemma \ref{thm:convergence:lem713}, $R_t$ is the
    sum of negatively correlated indicator functions and consequently,
    $\Varsub{\bar{1}}{R_t} \le \Esub{\bar{1}}(R_t}$
  so $$\Varsub{\bar{1}}{R_t} \le n/4$.
\item Set
  \[
    \sigma = \sqrt{\max{\Varsub{\pi}{W}, \Varsub_{\bar{1}}{\operatorname{W}(X_t)}}} =
    \frac{\sqrt{n}}{2}.
    \]
  \item Then
    \[
      \abs{\Esub{\pi}(W} - \Esub{\bar{1}}(\operatorname{W}(X_t)} } =
      \frac{n}{2} \left( 1 - \frac{1}{n} \right)^t = \sigma \sqrt{n}
      \left( 1 - \frac{1}{n} \right)^t.
    \]
  \item Set $t_n = \frac{1}{2}(n-1)\log n - (\alpha-1)n > \frac{1}{2}n
    \log n - \alpha n$ and using $(1-1/n)^{n-1} > \EulerE^{-1} > (1 -
    1/n)^n$
    \[
      \abs{\Esub{\pi}(W} - \Esub{\bar{1}}(\operatorname{W}(X_t)} }
  \EulerE^{\alpha-1} \sigma.
    \]
  \item Applying Lemma \ref{thm:convergence:prop79} gives
    \[
      d\left(\frac{1}{2} n \log n - \alpha n \right) \ge \|
      P^{t_n}(\bar{1}, \cdot) - \pi \|_{TV} \ge 1 - 8\EulerE^{2-2\alpha}.
  \end{enumerate}
\end{proof}
\subsection*{Continuous State Space and Point Process MCMC}

Consider three particles each randomly located in the square \( [0,1]^2
\subset \Reals^2 \) with positions \( (x_{i1}, x_{i2}) \) for \( i =
1,2,3 \). The state space is \( \mathcal{X} = [0,1]^6 \).  Suppose the
positions of the particles are distributed according to the density
\[
    \pi(x) = \pi(x_1,x_2,x_3) = \frac{1}{z} \exp\left[ -C \sum\limits_{i=1}^3
    \|x_i\| - \sum\limits_{i<j} \frac{1}{\| x_i - x_j \|} \right]
\] where \( \| \cdot \| \) is the usual Euclidean norm on \( \Reals^2 \),
\( C \) and \( D \) are fixed positive constants and \( z \) is the
normalizing constant or partition function.  In this density the first
sum pushes the particle towards the origin, the second sum pushes them
away from each other.

Using the Metropolis algorithm, create a Markov chain with \( \pi \) as
its stationary distribution.  Given \( X_n \), first choose \( y \in [0,1]^6
\) from the uniform distribution on \( \mathcal{X} \).  Then with
probability \( r = \min{1, \pi(y)/\pi(x)} \), accept \( X_{n+1} = y \),
otherwise reject \( y \) and \( X_{n+1} = x \).  Then this Markov chain
has \( \pi \) as its stationary distribution.

\begin{lemma}
    The Metropolis algorithm Markov chain for the \( 3 \) particle
    system with stationary distribution
    \[
        \pi(x) = \pi(x_1,x_2,x_3) = \frac{1}{z} \exp\left[ -C \sum\limits_
        {i=1}^3 \|x_i\| - \sum\limits_{i<j} \frac{1}{\| x_i - x_j \|}
        \right]
    \] satisfies a uniform minorization condition with \( n_0 = 1 \) and
    \( \epsilon = (0.488) \exp(-C(3 \sqrt{2}) - D(12 - 3/ \sqrt{2})) \)
\end{lemma}

\begin{remark}

\end{remark}
With \( 3 \sqrt{2} \approx 4.243 \) and \( 12 - 3/\sqrt{2} \approx 9.879
\), the estimate \( \epsilon = (0.488) \exp(-C(4.25) - D(9.88)) \) is
simpler.

\begin{proof}
    \begin{enumerate}
        \item
            To avoid configurations where the particles are close
            together, creating a near division by \( 0 \), set
            \[
                \mathcal{X}' = \setof{(x_1,x_2,x_3)}{\| x_i - x_j \| \ge
                1/4}.
            \]
        \item
            Being closed and bounded, the minimum value
            \[
                m = \min_{x,y \in \mathcal{X}} \frac{\pi(y)}{\pi(x)} > 0
            \] is assumed on \( \mathcal{X} \).
        \item
            Let \( A \subseteq \mathcal{X}' \).  Then from any state \(
            x \in \mathcal{X} \), the chain will move into \( A \) on
            the next step provided the proposed new configuration \( y \)
            is in \( A \) and that the proposed configuration is
            accepted according to the Bernoulli random variable.
        \item
            Hence
            \begin{align*}
                P(x,A) &= \int_A P(x,\df{y}) \\
                &= \int_A \min{1, \frac{\pi(y)}{\pi(x)}} \df{y} \\
                &\ge \int_{A \intersect \mathcal{X}'} m \df{y} \\
                & m
                \operatorname{Leb}
                (A \intersect \mathcal{X}')
            \end{align*}
            where \(
            \operatorname{Leb}
            (\cdot) \) is Lebesgue measure on \( \Reals^6 \).
        \item
            Set \( \epsilon =
            \operatorname{Leb}
            (\mathcal{X}') \) and \( \mu(A) =
            \operatorname{Leb}
            (A \intersect \mathcal{X}')/
            \operatorname{Leb}
            (\mathcal{X}') \), then \( \epsilon > 0 \) and \( \mu \) is
            a probability measure and the uniform minorization condition
            is satisfied.
        \item
            Numerical convergence bounds require estimation of \(
            \operatorname{Leb}
            (\mathcal{X}') \) and \( m \).
        \item
            In order for \( (x_1,x_2,x_3) \in \mathcal{X}' \), first
            choose \( x_1 \in [0,1]^2 \) with area \( 1 \).  Then choose
            any \( x_2 \in [0,1]^2 \setminus B(x_1, 1/4) \) with area
            greater than \( 1 - (\text{pi})(1/4)^2 \).  Finally choose
            any \( x_3 \in [0,1]^2 \setminus (B(x_1, 1/4) \union B(x_2,
            1/4)) \) with area \( 1 - 2 \cdot (\text{pi})(1/4)^2 \).  (Here
            \( B(x,r) \) is the ball in \( \Reals^2 \) with center \( x \)
            and radius \( r \) and \( (\text{pi}) \) is used instead of
            the traditional symbol to avoid confusion with the
            stationary distribution.  This is the only place so far in
            these notes where the notations have collided!)
        \item
            Hence \(
            \operatorname{Leb}
            (\mathcal{X}') \ge 1 (1 - 3.14/16)(1 - 3.14/8) \ge 0.488 \).
        \item
            For any \( x_{i}, x_j \in \mathcal{X}' \), \( 0 \le \|x\|
            \le \sqrt{2} \) and \( 1/4 \le \| x_i x_j\| \le \sqrt{2} \).
            Then \( 0 \le \sum\limits_{i=1}^3 \|x_i\|\le 3 \sqrt{2} \)
            and
            \[
                \frac{3}{\sqrt{2}} \le \sum\limits_{i<j} \frac{1}{\| x_i
                - x_j \|} \le 12.
            \] Then
            \[
                m \ge \frac{\EulerE^{-C \cdot (3 \sqrt{2}) - D(12)}}{\EulerE^
                {-C \cdot (0) - D(3/\sqrt{2})}} = \EulerE^{-C \cdot (3
                \sqrt{2}) - D(12- 3/\sqrt{2})}.
            \]
    \end{enumerate}
\end{proof}

\begin{remark}
    The proof can be modified to give slightly better estimates by
    taking the removed balls to have smaller radii.
\end{remark}

If \( C = D = \frac{1}{10} \), then \( \epsilon = 0.117 \) giving the
convergence bound
\[
    \|
    \operatorname{dist}
    (X_n) - \pi \|_{TV} \le (0.883)^n.
\] After \( 38 \) steps, the total variation distance between the Markov
chain and the stationary distribution is less than \( 0.01 \).

\subsection*{Pseudo-Minorization Conditions}

The coupling construction in the Minorization Estimate was a pairwise
construction, it only considered states \( x \) and \( y \) at a time.
Instead, replace \( \mu(\cdot) \) with \( \mu_{x,y}(\cdot) \) allowing
it to depend on \( x \) and \( y \).  Then \( C \) is called a
pseudo-small set and the Minorization Estimate Theorem continues to
hold.  See the exercises for the proof.  On a finite state space, choose
\[
    \epsilon = \min_{i,j \in \mathcal{X}}\sum_{z \in \mathcal{X}} \min_{i,j
    \in \mathcal{X}} \left[ (P^{n_0})_{i,z} (P^{n_0})_{j,z} \right] > 0
\] with
\[
    \mu_{i,j}(z) = \frac{\min_{i,j \in \mathcal{X}} \left[ (P^{n_0})_{i,z}
    (P^{n_0})_{j,z} \right]}{\sum_{\nu \in \mathcal{X}} \min_{i,j \in
    \mathcal{X}} \left[ (P^{n_0})_{i,z} (P^{n_0})_{j,z} \right] }.
\] Then the chain will satisfy an \( n_0 \)-minorization condition, for
all \( i,j,z \in \mathcal{X} \), \( (P^{n_0})_{i,z} \ge \epsilon \mu_{i,j}
(z) \) and \( (P^{n_0})_{j,z} \ge \epsilon \mu_{i,j}(z) \).  Then again
\[
    \|
    \operatorname{dist}
    (X_n) - \pi \|_{TV} \le (1-\epsilon)^{\lfloor n/n_0 \rfloor}.
\]

\begin{example}
    Consider the random walk on the \( 3 \times 3 \) square lattice. In \(
    P^2 \), the minimum values of \( \sum_{z \in \mathcal{X}} \min_{i,j
    \in \mathcal{X}} \left[ (P^{n_0})_{i,z} (P^{n_0})_{j,z} \right] \)
    occur at \( (i,j) = (3,7) \) and \( (1,9) \), corresponding to
    opposite corners of the square lattice.  Then calculating (see the
    exercises) \( \epsilon = \frac{1}{3} \).  Therefore
    \[
        \|
        \operatorname{dist}
        (X_n) - \pi \|_{TV} \le (1-\frac{1}{3})^{\lfloor n/2 \rfloor} =
        \left( \frac{2}{3} \right)^{\lfloor n/2 \rfloor}
    \] To get the distribution of the random walk within \( 0.01 \) of
    the stationary distribution requires \( 24 \) steps.  Compare this
    to the estimates of \( 78 \) steps with the Minorization Condition,
    and \( 6 \) step using the eigenvalues of \( P \).
\end{example}

\subsection*{Unbounded State Spaces}

The uniform minorization condition gives a good quantitative convergence
bound.  However, often on unbounded state spaces, the minorization
condition cannot be satisfied uniformly, only on some subset \( C
\subset \mathcal{X} \).  In such cases, adjust the previous \( n_0 = 1 \)
coupling construction, as follows.  First choose \( X0 \sim \mu(\cdot) \)
and \( X_0' \sim \pi(\cdot) \) independently, and then inductively for \(
n = 0, 1, 2, \dots \):
\begin{enumerate}
    \item
        If \( X_n = X_n' \), choose \( X_{n+1} = X_{n+1}' \sim P(X_n,
        \cdot) \).
    \item
        Else, if \( (X_n , X_n') \in C \times C \), flip a coin whose
        probability of Heads is \( \epsilon \), and then update \( X_{n+1}
        \) and \( X_{n+1}' \) in the same way as in step 2 of the
        previous uniform minorization construction.
    \item
        Else, if \( (X_n, X_n' ) \notin C \times C \), then
        conditionally independently choose \( X_{n+1} \sim P(X_n, \cdot)
        \) and \( X_{n+1}' \sim P(X_n', \cdot) \), i.e., the two chains
        are simply updated independently.
\end{enumerate}

The above construction provides good coupling bounds provided that the
two chains return to \( C \times C \) often enough, but this last
property is difficult to guarantee.  Thus, to get convergence bounds,
the Markov chian needs a drift condition.  Basically, the drift
condition guarantees that the chains will return to \( C \times C \)
quickly enough to still achieve a coupling.

\begin{definition}
    A Markov chain with a small set \( C \subseteq X \) satisfies a
    \defn{bivariate drift condition} if there exists a function
    \[
        h :  \mathcal{X} \times \mathcal{X} \to [1, \infty)
    \] and some \( \alpha > 1 \) such that \( \bar{P}h(x,y) \le h(x,y)/\alpha
    \) for \( (x,y) \notin C \times C \) where
    \[
        \bar{P}h(x,y)= \E{h(X_{n+1}, Y_{n+1}) \given X_n = x, Y_n = y}
    \] is the expected value of \( h(X_{n+1}, Y_{n+1}) \) on the next
    iteration, when the chains start from \( x \) and \( y \)
    respectively.
\end{definition}

Next define the quantity
\[
    B_{n_0} = \max{1, \alpha^{n_0}(1-\epsilon) \bar{R}h}
\] where
\[
    \bar{R}h(x,y) = \int_{\mathcal{X}} \int_{\mathcal{X}} (1-\epsilon)^2
    h(z,w) \left[ P^{n_0}(x, \df{z}) - \epsilon \mu(\df{z}) \right]
    \left[ P^{n_0}(y, \df{w}) - \epsilon \mu(\df{w}) \right].
\] The expression \( \bar{R}h(x,y) \) represents the expected value of \(
h(X_{n+{n_0}}, X_{n+{n_0}}) \) given that \( X_n - x \)and \( X_n' = y \)
and that the two chains fail to couple at time \( n \), meaning the coin
comes up Tails.

\begin{theorem}
    Consider a Markov chain on \( \mathcal{X} \), with \( X_0 = x \) and
    transition probabilities \( P \).  Suppose the minorization and
    bivariate drift conditions hold for some \( C \subseteq \mathcal{X} \),
    \( h :  \mathcal{X} \times \mathcal{X} \to [1, \infty] \),
    probability distribution \( \mu \), \( \alpha > 1 \), \( \epsilon >0
    \).  Then for any integers, \( 1 \le j \le n \) with \( B_{n_0} \)
    as above,
    \[
        \|
        \operatorname{dist}
        (X_n) - \pi \|_{TV} \le (1-\epsilon)^j + \alpha^{-n} B_{n_0}^{j-1}
        \Esub{Z \sim \pi}[h(x,Z)].
    \]

\end{theorem}

\begin{proof}[Sketch]
    \begin{enumerate}
        \item
            Create a second copy of the Markov chain with \( X_0' \sim
            \pi \) and use the coupling construction.
        \item
            Let \( N_n \) be the number of times the chain \( (X_n, X_n')
            \) is in \( C \times C \) by the \( n \)th step.
        \item
            Then by the coupling inequality.
            \begin{align*}
                \|
                \operatorname{dist}
                (X_n) - \pi \|_{TV} &\le \Prob{X \ne X_n'} \\
                &\le \Prob{X \ne X_n', N_{n-1} \ge j} | \Prob{X \ne X_n',
                N_{n-1} <j}
            \end{align*}
        \item
            The first term suggests the chains have not coupled by time \(
            n \) despite visiting \( C \times C \) at least \( j \)
            times.  Since each such time gives them a chance of \(
            \epsilon \) to couple, the first term is less or equal to \(
            (1 - \epsilon)^j \).
        \item
            The second term is more complicated, but from the bivariate
            drift condition together with a martingale argument, it can
            be shown to be no greater than
            \[
                \alpha^{-n} B_{n_0}^{j-1} \Esub{Z \sim \pi}[h(x,Z)].
            \]
    \end{enumerate}
\end{proof}

Sometimes it could be hard to directly check the bivariate drift
condition so introduce the more easily-verified univariate drift
condition.  This gives a way to derive the bivariate condition from the
univariate one.

\begin{definition}
    A Markov chain with a small set \( C \) satisfies a \defn{univariate
    drift condition}%
    \index{univariate drift condition}
    if there are constants \( 0 < \lambda < 1 \) and \( b < \infty \)
    and a function \( V :  \mathcal{X} \to [1, \infty] \) such that
    \[
        PV(x) \le \lambda V(x) + b \indicator{C}(x)
    \] where \( PV(x) = \E{V(X_{n+1}) \given X_n = x} \).
\end{definition}

The univariate drift condition can be used to bound \( \Esub{\pi}{V} \)
in the following way.  Assuming \( \Esub{\pi}{V} < \infty \),
stationarity then implies \( \Esub{\pi}{V} \le \Esub{\pi}{V} + b \) so
then \( \Esub{\pi}{V} \le b/(1-\lambda) \).

\begin{proposition}
    Suppose:
    \begin{enumerate}
        \item
            The univariate drift condition is satisfied for some
            \begin{itemize}
                \item
                    \( V :  \mathcal{X} \to [1,\infty] \),
                \item
                    \( C \in \mathcal{X} \),
                \item
                    \( 0 < \lambda < 1 \),
                \item
                    \( b < \infty \).
            \end{itemize}
        \item
            \( d > ( b/(1-\lambda)) - 1 \).
    \end{enumerate}
    Then the bivariate drift condition is satisfied for the same \( C \)
    with \( h(x,y) = \frac{1}{2}[ V(x) + V(y)] \) and \( \alpha =
    \lambda + b/(d + 1) \).
\end{proposition}

\begin{proof}
    \begin{enumerate}
        \item
            Assume \( (x,y) \notin C \times C \).  Then either \( x
            \notin C \) or \( y \notin C \), so \( h(x,y) \ge (1 + d)/2 \).
        \item
            The univariate drift condition applied separately to \( x \)
            and \( y \) implies that \( PV(x) + PV(y) \le \lambda V(x) +
            \lambda V(y) + b \).
        \item
            Therefore,
            \begin{align*}
                \bar{P}h(x,y) &= \frac{1}{2}
                \left[ PV(x) + PV(y) \right] \\
                &\le \frac{1}{2} \left[ \lambda V(x) + \lambda V(y) + b
                \right] \\
                &= \lambda h(x,y) + b/2 \\
                &\le \lambda h(x,y) + (b/2) \left[ h(x,y)/((1+d)/2)
                \right] \\
                &= \left[ \lambda + b/(1+d) \right] h(x,y).
            \end{align*}
    \end{enumerate}
\end{proof}

\begin{example}

    Let the state space be \( \mathcal{X} = \Reals \) with target
    density the double exponential or Laplace distribution. \( \pi(x) =
    \EulerE^{-\abs{x}}/2 \).  It is easy to simulate the double
    exponential density using the standard technique of choosing a
    uniform random deviate and then applying the inverse of the
    cumulative distribution function, so this is an illustrative example
    rather than a practical simulation method for this

    Use another version of the Metropolis algorithm.  Choose the initial
    state \( x_0 \) uniformly at random from the interval \( [ -2, +2] \).
    At succeeding steps, first propose to move from state \( x \) to \(
    y \) chosen uniformly at random from the interval \( [x - 2, x + 2] \).
    With probability \( \min{1, \pi(y)/\pi(x)} \), accept the proposal \(
    y \) which becomes the new state, otherwise reject it and remain at \(
    x \).  Again, this procedure creates a Markov chain with \( \pi \)
    as its stationary distribution.

    To apply Theorem 2 requires minorization and drift conditions
    following from the next two lemmas.

    \begin{lemma}
        The Markov chain for sampling for the double exponential
        distribution satisfies a minorization condition with \( C = [-2,
        2] \), \( n_0 = 2 \), \( \epsilon = 1/(8 EulerE^2) \), and \(
        \mu(A) = \frac{1}{2}
        \operatorname{Leb}
        (A \intersect [-1,1]) \), where \(
        \operatorname{Leb}
        \) is Lebesgue measure on \( \Reals \).
    \end{lemma}

    \begin{proof}
        \begin{enumerate}
            \item
                Let \( x \in C \), Without loss of generality assume \(
                x \ge 0 \).
            \item
                First consider \( B \subset [-1,1] \) and let \( z \in [0,1]
                \) and \( y \in B \).
            \item
                Then \( [0,1] \subseteq [x-2, x+2] \) and \( B \subseteq
                [z-2, z+2] \).
            \item
                Hence the proposed density \( q \) satisfies \( q(z,z) =
                q(z,) = \frac{1}{2} \).
            \item
                Also, \( \pi(x) \le \EulerE^0 = 1 \) and \( \EulerE^{-1}
                \le \pi(y) \le 1 \) and \( \pi(z) \ge \EulerE^{-1} \),
                so if \( \alpha(x,z) = \min[1, \frac{\pi(z)}{\pi(x)}] \)
                is the probability of accepting a proposed move from \(
                x \) to \( z \), then \( \alpha(x,z) \ge \EulerE^{-1} \)
                and \( \alpha(z,x) \ge \EulerE^{-1} \).
            \item
                Then
                \begin{multline*}
                    P^2(x,B) \ge \int_B \int\limits_{x-2}^{x_2} q(x,z) q
                    (z,x) \alpha(z,y) \df{x} \df{y} \\
                    \ge \int_B \int_0^1 \frac{1}{4} \cdot \frac{1}{\EulerE}
                    \cdot \frac{1}{4} \cdot \frac{1}{\EulerE} \df{z} \df
                    {y} = \frac{1}{16 \EulerE^2}
                    \operatorname{Leb}
                    (B).
                \end{multline*}
            \item
                Finally for any \( A \subseteq \Reals \)
                \[
                    P^2(x,A) \ge P^2(x,A \intersect [-1,1]) \ge \frac{1}
                    {16 \EulerE^2}
                    \operatorname{Leb}
                    (A \intersect [-1,1]) = \frac{1}{8 \EulerE^2} \mu(A).
                \]
        \end{enumerate}
    \end{proof}

    \begin{lemma}
        The Markov chain for sampling for the double exponential
        distribution satisfies a univariate drift condition with \( V(x)
        - \EulerE^{-\abs{x}/2} \), \( C = [-2,2] \), \( \lambda = 0.916 \),
        and \( b = 0.285 \).
    \end{lemma}

    \begin{proof}
        \begin{enumerate}
            \item
                Without loss of generality, assume \( x \ge 0 \).
            \item
                Note
                \[
                    PV(x) = \int\limits_{x-2}^{x+2} q(x,y) \abs{ V(y)
                    \alpha(x,y) + V(x)( 1 - \alpha(x,y))} \df{y}.
                \]
            \item
                First compute the integral on \( x \le y \le x + 2 \).
                Here \( \alpha(x,y) = \frac{\pi(y)}{\pi(x)} = \frac{\EulerE^
                {-y}}{\EulerE^{-x}} = \EulerE^{x-y} \) and \( q(x,y) =
                \frac{1}{4} \).
            \item
                \begin{align*}
                    &\int\limits_{x}^{x+2} q(x,y) \abs{ V(y) \alpha(x,y)
                    + V(x)( 1 - \alpha(x,y))} \df{y} \\
                    &\qquad = \int\limits_x^{x+2} \frac{1}{4} \EulerE^{y/2}
                    \EulerE{x-y} \df{y} + \int\limits_x^{x+2} \frac{1}{4}
                    \EulerE^{x/2} (1 - \EulerE^{x-y}) \df{y} \\
                    &\qquad = \int\limits_x^{x+2} \EulerE^{-y/2} \df{y}
                    + \frac{1}{4} \EulerE^{x/2}\cdot 2 - \frac{1}{4}
                    \EulerE^{3x/2} \int\limits_x^{x+2} \EulerE^{-y} \df{y}
                    \\
                    &\qquad = \frac{1}{4} \EulerE^x \left[ -2 \EulerE^{-
                    (x+2)/2} + 2 \EulerE^{-x/2}\right] + \frac{1}{4}
                    \EulerE^{x/2}\cdot 2 - \frac{1}{4} \EulerE^{3x/2}
                    \left[ -\EulerE^{-x-2} + \EulerE^{-x} \right] \\
                    &\qquad = \frac{1}{4} \EulerE^{x/2} \left[ -2\EulerE^1
                    + 2 + 2 + \EulerE^{-2} - 1 \right] \\
                    &\qquad \frac{1}{4} \left[ 3 + \EulerE^{-2} - 2\EulerE^
                    {-1} \right] V(x) = \lambda_1 V(x)
                \end{align*}
                by setting \( \frac{1}{4} \left[ 3 + \EulerE^{-2} - 2\EulerE^
                {-1} \right] \approx 0.6 \).
            \item
                Case 1:  \( x \in (2,\infty) \) where \( (2,\infty) \not\subseteq
                [-2,2] \).  Then \( \alpha(x,y) = \min{1, \frac{\EulerE^
                {-abs{y}}}{\EulerE^{-\abs{x}}}} = 1 \) for all \( y \in
                [x-2,2] \) so
                \begin{multline*}
                    PV(x) = \int_{x-2}^x q(x,y) V(y) \df{y} + \lambda_1
                    V(x) = \\
                    \frac{1}{4} \int_{x-2}^x \EulerE^{y/2} \df{y} =\\
                    \frac{}{1/4} \EulerE^{x/2}\cdot 2 \cdot (1 - \EulerE^
                    {-1}) + \lambda_1 V(x) = (\frac{1}{2}(1-\EulerE^{-1})
                    + \lambda_1) V(x) \le 0.916 V(x)
                \end{multline*}
            \item
                Case 2:  \( x \in [1,2] \subseteq C \).  Again \( \alpha
                (x,y) = 1 \) for all \( y \in [x-2,x] \), so
                \begin{multline*}
                    PV(x) = \int_{x-2}^x q(x,y) V(y) \df{y} + \lambda_1
                    V(x) = \\
                    \frac{1}{4} \left( \int_{x-2}^x \EulerE^{-y/2} \df{y}
                    + \int_0^x \EulerE^{y/2} \df{y} \right) + \lambda_1
                    V(x) =\\
                    \frac{1}{4} \left( \int_{0}^{2-x} \EulerE^{y/2} \df{y}
                    + \int_0^x \EulerE^{y/2} \df{y} \right) + \lambda_1
                    V(x) =\\
                    \frac{1}{2} \left( (\EulerE^{x/2} + \EulerE^{1-x/2})
                    - 1 + \lambda_1 \EulerE^{x/2} \right).
                \end{multline*}
            \item
                Let \( z = \EulerE^{x/2} \).  Then numerically
                \[
                    \max_{x \in [1,2]} \left[ PV(x) - 0.916 V(x)\right]
                    = \max_{z\in [\sqrt{\EulerE}, \EulerE]} \left[ \frac
                    {1}{2} \left(z + \frac{\EulerE}{z}\right) - 1 +
                    \lambda_1 z -0.916 z \right] \le 0.13.
                \]
            \item
                Case 3:  \( x \in [0,1] \subseteq C \).  Then \( \alpha(x,y)
                = 1 \) for any \( y \in [-x,x] \).
                \begin{align*}
                    &\int\limits_{x-2}^{-x} \left[ q(x,y) \alpha(x,y) V(y)
                    + q(x,y) ( 1 - \alpha(x,y))V(x) \right] \df{y} \\
                    &\qquad \qquad + \int_x^x q(x,y) V(y) \df{y} +
                    \lambda_1 V(x) \\
                    &= \frac{1}{4} \EulerE^{x/2} \int_x^{2-x} \left(
                    \EulerE^{(x-y)/2} + 1 - \EulerE^{x-y} \right) \df{y}
                    + \frac{1}{2} \int_0^x \EulerE^{y/2} \df{y} +
                    \lambda_1 \EulerE^{x/2} \\
                    &= \frac{1}{4} \EulerE^{x/2} \left[ -2\EulerE^{x-1}
                    + \EulerE^{2(x-1)} - 2x + 3 \right] + \EulerE^{x/2}
                    - 1 + \lambda_1 \EulerE^{x/2}.
                \end{align*}
            \item
                Computing numerically,
                \[
                    \max_{x \in [0,1]}\left[ PV(x) - 0.916 V(x) \right]
                    \le 0.285.
                \]
            \item
                Combining these three cases and the symmetric versions
                for \( x < 0 \) shows that the univariate drift
                condition
                \[
                    PV(x) \le 0.916 V(x) + 0.285 \indicator{C}(x)
                \] holds for all \( x \in \mathcal{X} \).
        \end{enumerate}
    \end{proof}

    With these two lemmas apply the Proposition to derive a bivariate
    drift condition.  Note that here \( d = \inf_{x = C^C} V(x) =
    \EulerE \), and \( b/(1-\lambda) - 1 = 2.39 < \EulerE \).  So \( h(x,y)
    = \frac{1}{2}(V(x) + V(y)) \) satisfies a bivariate drift condition
    with \( \alpha^{-1} = \lambda + b/(d + 1) = 0.916 + 0.285/(\EulerE +
    1) \approx 0.993 \).

    To bound \( B_{n_0} = B_2 \), let \( D = [-6, 6] \).  Then \( P^2(x,D)
    = 1 \) for any \( x \in C \).  Thus
    \[
        \sup_{(x,y) \in C \times C} \bar{R} h(x,y) \le \sup_{(x,y) \in D
        \times D}h(x,y) = \sup_{x \in D} V(x) = \EulerE^3 < 20.1.
    \] So
    \[
        B_2 = \max{1, \alpha^2(1-\epsilon) \sup \bar{R} h} < (0.993)^{-2}
        \left(1 - \frac{1}{8 \EulerE^2} \right) (20.1) \approx 20.04.
    \]

    Let \( X_0 = 0 \), then
    \begin{multline*}
        \Esub{X \sim \pi}{h(0,Z)} = \Esub{X \sim \pi}{\frac{1}{2} \left(
        V(0) + V(Z) \right) }= \\
        \frac{1}{2} + \frac{1}{2} \frac{\int_{y \in \mathcal{X}} \EulerE^
        {\abs{y}/2 \EulerE^{-\abs{y}}} \df{y}}{\int_{y \in \mathcal{X}}
        \EulerE^{-\abs{y}}} \df{y} = \frac{1}{2} + \frac{1}{2} \cdot
        \frac{2}{1} = 2 (??)
    \end{multline*}
    An alternative estimation is instead to use the bound \( \Esub{X
    \sim \pi}{V} \le b/(1-\lambda) = 3.939 \), as above.  Therefore,
    using the Theorem
    \begin{align*}
        \|
        \operatorname{dist}
        (X_n) - \pi \|_{TV} &\le (1- \epsilon)^j + \alpha^{-n} B_2^{j-1}
        \Esub{X \sim \pi}{h(0,Z)} \\
        &\le (0.983)^{1 + n/439.56} + (2 \cdot (20.04)^{n/439.56})(0.993)^n.
    \end{align*}
    For example, setting \( n = 120{,}000 \) and \( j = 274 = 1+ n/439 \)
    the upper bound is
    \[
        \|
        \operatorname{dist}
        (X_n) - \pi \|_{TV} \le (0.983)^{1 + n/439.56} + (2 \cdot (20.04)^
        {n/439.56})(0.993)^n
    \] so that after \( 120{,}000 \) steps, the total variation distance
    between the Markov chain and the stationary distribution is less
    than \( 0.01 \).  The R script in the Algorithms section shows that
    after about \( 48{,}000 \) steps total variation distance between
    this Markov chain and the stationary distribution is less than \(
    0.05 \).  Either way, the convergence to a stationary distribution
    is much slower than other examples.

\end{example}
\visual{Section Starter Question}{../../../../CommonInformation/Lessons/question_mark.png}
\section*{Section Ending Answer}

\subsection*{Sources} This section is adapted from:

\nocite{}
\nocite{}

\hr

\visual{Algorithms, Scripts, Simulations}{../../../../CommonInformation/Lessons/computer.png}
\section*{Algorithms, Scripts, Simulations}

\subsection*{Algorithm}

\subsection*{Scripts}

% \input{ _scripts}

\hr

\visual{Problems to Work}{../../../../CommonInformation/Lessons/solveproblems.png}
\section*{Problems to Work for Understanding}
\renewcommand{\theexerciseseries}{}
\renewcommand{\theexercise}{\arabic{exercise}}

\begin{exercise}
    Prove the Minorization Condition Theorem under the less restrictive
    pseudo-minorization condition.
\end{exercise}
\begin{solution}
To be done.
\end{solution}
% \begin{exercise}
%     \begin{enumerate}[label=(\alpha*)]
%     \item
% \end{enumerate}
% \end{exercise}
% \begin{solution}
%     \begin{enumerate}[label=(\alpha*)]
%     \item
% \end{enumerate}
% \end{solution}

\hr

\visual{Books}{../../../../CommonInformation/Lessons/books.png}
\section*{Reading Suggestion:}

\bibliography{../../../../CommonInformation/bibliography}

%   \begin{enumerate}
%     \item
%     \item
%     \item
%   \end{enumerate}

\hr

\visual{Links}{../../../../CommonInformation/Lessons/chainlink.png}
\section*{Outside Readings and Links:}
\begin{enumerate}
    \item
    \item
    \item
    \item
\end{enumerate}

\section*{\solutionsname} \loadSolutions

\hr

\mydisclaim \myfooter

Last modified:  \flastmod

\end{document}

%%% Local Variables:
%%% TeX-master: t
%%% End:
